# Multilayer-Perceptron-for-Letter-Recognition-UCI-dataset-
The hidden layer is sigmoidal. But output is softmax as this is classification problem. So, we are supposed to find maximum probability in the output vector which corresponds to the predicted letter. Loss function is cross entropy function. Very low weights are initialized to prevent net from exploding. A low learning is important as this high dimensional data. Training set contains 80% of data and test is 20% of the total dataset. One input, one hidden and one output layer. Inputs are vectors each having 16 attributes that characterize a letter. 16 input units and 26 output units which are in the form of binary vectors, e.g letter A can be written as [1,0,0…….0]  Good learning rate is crucial. Learning is through backpropagation. Implemented in Java  Classification rate is about 71.42%
